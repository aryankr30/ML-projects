{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TASK 1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN1P8at7O/85Vf8xXvJHBI2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryankr30/ML-projects/blob/main/TASK_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***LOGISTIC REGRESSION FOR BINARY CLASSIFICATION FROM SCRATCH***"
      ],
      "metadata": {
        "id": "qoZfVMot771Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 507,
      "metadata": {
        "id": "BAb86iBM_LZB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression:\n",
        "    def __init__(self, learning_rate=0.01, n_iters=1000000):\n",
        "        self.lr = learning_rate\n",
        "        self.n_iters = n_iters\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # initializing parameters\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # gradient descent\n",
        "        for i in range(self.n_iters):\n",
        "            # approximate y with linear combination of weights and x, plus bias\n",
        "            linear_model = np.dot(X, self.weights) + self.bias\n",
        "            # apply sigmoid function\n",
        "            y_predicted = self._sigmoid(linear_model)\n",
        "            \n",
        "            #cost function\n",
        "            cost = -(1/n_samples)*np.sum( y*np.log(y_predicted) + (1-y)*np.log(1-y_predicted))\n",
        "\n",
        "            # compute gradients\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
        "            db = (1 / n_samples) * np.sum(y_predicted - y)\n",
        "            # update parameters\n",
        "            self.weights -= self.lr * dw\n",
        "            self.bias -= self.lr * db\n",
        "\n",
        "            #keeping track of cost function value\n",
        "            if(i%(self.n_iters/10) == 0):\n",
        "               print(\"cost after \", i, \"iteration is : \", cost)\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        y_predicted = self._sigmoid(linear_model)\n",
        "        y_predicted_cls = [1 if i >= 0.5 else 0 for i in y_predicted]\n",
        "        return np.array(y_predicted_cls)\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "9WUfCqGqVnXc"
      },
      "execution_count": 508,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "_aKEWD58VsGJ"
      },
      "execution_count": 509,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(X): \n",
        "    # m-> number of training examples\n",
        "    # n-> number of features \n",
        "    m, n = X.shape\n",
        "    \n",
        "    # Normalizing all the n features of X\n",
        "    for i in range(n):\n",
        "        X = (X - X.mean(axis=0))/X.std(axis=0)\n",
        "        \n",
        "    return X"
      ],
      "metadata": {
        "id": "UyyAgMYAKyUM"
      },
      "execution_count": 510,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"crack_detection.csv\")\n",
        "y1=df.iloc[:,24]\n",
        "x1=df.iloc[:,1:24]\n",
        "x1=np.array(x1)\n",
        "y1=np.array(y1)\n",
        "\n",
        "#splitting of datasets into 60%,20%,20% as train set ,test set, validation set\n",
        "x_train, x_Combine, y_train, y_Combine = train_test_split(x1,y1,train_size=0.6,random_state=11,shuffle=True)\n",
        "\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_Combine,y_Combine,test_size=0.5,random_state=1)\n",
        "\n",
        "\n",
        "#Normalization            \n",
        "X_train=normalize(x_train)\n",
        "X_test=normalize(x_test)\n",
        "X_val=normalize(x_val)\n",
        "\n",
        "regressor = LogisticRegression(learning_rate=0.01, n_iters=1000000)\n",
        "regressor.fit(X_train, y_train)\n",
        "y_test_pred = regressor.predict(X_test)\n",
        "y_val_pred = regressor.predict(X_val)\n",
        "y_train_pred=regressor.predict(X_train)\n",
        "\n",
        "#accuracy using user defined function\n",
        "print(\"accuracy of training set\", accuracy(y_train, y_train_pred)*100)\n",
        "print(\"accuracy of validating set\", accuracy(y_val, y_val_pred)*100)\n",
        "print(\"accuracy of testing set\", accuracy(y_test, y_test_pred)*100)\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "#f1 score using sklearn\n",
        "print(\"f1 score of training set\", f1_score(y_train, y_train_pred)*100)\n",
        "print(\"f1 score of validating set\", f1_score(y_val, y_val_pred)*100)\n",
        "print(\"f1 score of testing set\", f1_score(y_test, y_test_pred)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38XIX7Y5VtYG",
        "outputId": "b50df3b3-9a2b-4dc0-d12a-4efe17eb98c4"
      },
      "execution_count": 511,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cost after  0 iteration is :  0.6931471805599453\n",
            "cost after  100000 iteration is :  0.28456020033833296\n",
            "cost after  200000 iteration is :  0.25611149005809125\n",
            "cost after  300000 iteration is :  0.24028860566616914\n",
            "cost after  400000 iteration is :  0.23017783608983808\n",
            "cost after  500000 iteration is :  0.22325777550026796\n",
            "cost after  600000 iteration is :  0.21829091615864352\n",
            "cost after  700000 iteration is :  0.21459495407404502\n",
            "cost after  800000 iteration is :  0.21176469023285033\n",
            "cost after  900000 iteration is :  0.20954599676049468\n",
            "accuracy of training set 91.42857142857143\n",
            "accuracy of validating set 84.28571428571429\n",
            "accuracy of testing set 79.28571428571428\n",
            "f1 score of training set 91.96428571428572\n",
            "f1 score of validating set 84.93150684931507\n",
            "f1 score of testing set 81.29032258064515\n"
          ]
        }
      ]
    }
  ]
}