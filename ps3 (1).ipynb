{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ps3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i76ORASSEIIG",
        "outputId": "f5c42a39-87ce-461c-8577-68e1590faf15"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/kaggle\""
      ],
      "metadata": {
        "id": "HYIEpScnEejX"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/My Drive/kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM2CqsgwEp4a",
        "outputId": "e6af3174-7f95-497b-c1cb-77be51964cab"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/kaggle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c dog-breed-identification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KdxRUSRFArU",
        "outputId": "4894f0f0-b08c-4606-921a-9648225d8477"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dog-breed-identification.zip to /content/gdrive/My Drive/kaggle\n",
            " 99% 685M/691M [00:05<00:00, 127MB/s]\n",
            "100% 691M/691M [00:05<00:00, 124MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \\*.zip  && rm *.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMPYQ7tjGo5L",
        "outputId": "a51356ec-98fe-47b9-ac5c-29c594955cf4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  dog-breed-identification.zip\n",
            "replace labels.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "qre0TJcJALwI",
        "outputId": "1d454cfb-ae9a-4a1a-a006-26891f9fb351"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-6456514d17e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mbreed_to_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mcode_to_breed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0mbreed_to_code\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rank'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'breed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mlabels_pivot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'breed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'breed'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from skimage import io\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "import tensorflow as tf\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "labels = pd.read_csv('https://drive.google.com/file/d/1-2PurAI18uOOLFfo9oySYT0VVfR9AFc4/view?usp=sharing')\n",
        "labelnames = pd.read_csv('https://drive.google.com/file/d/1-1ZxXjbu9zZgHu1_V2UDqGO1YzOvjN46/view?usp=sharing').keys()[1:]\n",
        "#print(\"Train folder has \", len(os.listdir(PATH+'train')),'images which matches with label\\'s', len(labels),'images')\n",
        "\n",
        "codes = range(len(labelnames))\n",
        "breed_to_code = dict(zip(labelnames, codes))\n",
        "code_to_breed = dict(zip(codes, labelnames))\n",
        "labels['target'] =  [breed_to_code[x] for x in labels.breed]\n",
        "labels['rank'] = labels.groupby('breed').rank()['id']\n",
        "labels_pivot = labels.pivot('id', 'breed', 'target').reset_index().fillna(0)\n",
        "\n",
        "train = labels_pivot.sample(frac=0.85)\n",
        "test = labels_pivot[~labels_pivot['id'].isin(train['id'])]\n",
        "\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize((224,224), interpolation=torchvision.transforms.InterpolationMode.BICUBIC),\n",
        "                                transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5 ))])\n",
        "\n",
        "class DogBreedDataset(Dataset):\n",
        "    'Characterizes a dataset for PyTorch'\n",
        "    def __init__(self, img_dir, label, transform):\n",
        "        'Initialization'\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.label)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.label is not None:\n",
        "            img_name = '{}.jpg'.format(self.label.iloc[index, 0])\n",
        "            fullname = self.img_dir + img_name\n",
        "            image = Image.open(fullname)\n",
        "            label = self.label.iloc[index, 1:].astype('float').to_numpy()\n",
        "            label = np.argmax(label)\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return [image, label]\n",
        "\n",
        "\n",
        "train_img = DogBreedDataset('https://drive.google.com/drive/folders/1G_en_EynMGODZKVR4YSbgiO3jWNIzdtF?usp=sharing', train, transform = transform)\n",
        "test_img = DogBreedDataset('https://drive.google.com/drive/folders/1G_en_EynMGODZKVR4YSbgiO3jWNIzdtF?usp=sharing', test, transform = transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_img,\n",
        "                                            batch_size = 128,\n",
        "                                            shuffle = True,\n",
        "                                            num_workers = 0)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(test_img,\n",
        "                                           batch_size = 128,\n",
        "                                           shuffle = False,\n",
        "                                           num_workers = 0)\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda' \n",
        "else:\n",
        "  device = 'cpu'\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding = 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding = 1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding = 1)\n",
        "    \n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "    \n",
        "        self.fc1 = nn.Linear(128 * 28 * 28,500 )\n",
        "        self.fc2 = nn.Linear(500, 120)\n",
        "    \n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "\n",
        "        x = x.view(-1, 128 * 28 * 28)\n",
        "    \n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# instantiate the CNN\n",
        "net = Net()\n",
        "\n",
        "# move tensors to GPU if CUDA is available\n",
        "net.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "epoch_log = []\n",
        "loss_log = []\n",
        "accuracy_log = []\n",
        "\n",
        "# Iterate for a specified number of epochs\n",
        "for epoch in range(epochs):  \n",
        "    print(f'Starting Epoch: {epoch+1}...')\n",
        "\n",
        "    running_loss = 0.0\n",
        "    # Each cycle is a minibatch\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Move our data to GPU\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward -> backprop + optimize\n",
        "        outputs = net(inputs) \n",
        "        loss = criterion(outputs, labels) \n",
        "        loss.backward() \n",
        "        optimizer.step()\n",
        "\n",
        "        # Print Training statistics - Epoch/Iterations/Loss/Accuracy\n",
        "        running_loss += loss.item()\n",
        "        if i % 50 == 49:    \n",
        "            correct = 0 \n",
        "            total = 0 \n",
        "\n",
        "            with torch.no_grad():\n",
        "                # Iterate through the testloader iterator\n",
        "                for data in testloader:\n",
        "                    images, labels = data\n",
        "                    # Move our data to GPU\n",
        "                    images = images.to(device)\n",
        "                    labels = labels.to(device)\n",
        "                    \n",
        "                    # Foward propagate our test data batch through our model\n",
        "                    outputs = net(images)\n",
        "\n",
        "                    _, predicted = torch.max(outputs.data, dim = 1)\n",
        "                    # Keep adding the label size or length to the total variable\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "                accuracy = 100 * correct / total\n",
        "                epoch_num = epoch + 1\n",
        "                actual_loss = running_loss / 50\n",
        "                print(f'Epoch: {epoch_num}, Mini-Batches Completed: {(i+1)}, Loss: {actual_loss:.3f}, Test Accuracy = {accuracy:.3f}%')\n",
        "                running_loss = 0.0\n",
        "\n",
        "    # Store training stats after each epoch\n",
        "    epoch_log.append(epoch_num)\n",
        "    loss_log.append(actual_loss)\n",
        "    accuracy_log.append(accuracy)\n",
        "\n",
        "print('Finished Training')"
      ]
    }
  ]
}